# DataCamp_projects
In this repository, I will be putting all the DataCamp projects I solve:

## 1st project: Book Recommendations from Charles Darwin
In the notebook, we will automatically detect how closely related Charles Darwin's books are to each other. We will develop the bases of a **content-based book recommendation system**, which will determine which books are close to each other based on how similar the discussed topics are using **NLP**.

## 2nd project: Classify Song Genres from Audio Data
In the notebook, we'll be examining data compiled by a research group known as The Echo Nest. Our goal is to look through this dataset and **classify songs** as being either 'Hip-Hop' or 'Rock' - all without listening to a single one ourselves. In doing so, we will learn how to clean our data, do some exploratory data visualization, and use feature reduction towards the goal of feeding our data through some simple machine learning algorithms: **Decision trees and logistic regression**

## 3rd project: Do Left-handed People Really Die Young?
This notebook will use pandas and Bayesian statistics to analyze the probability of being a certain age at death given that you are reported as left-handed or right-handed.


## 4th project:  Draw Flowers Using Mathematics
As the name of the project says, the notebook will use the **ggplot2 library of R** to draw mathematical functions such as sin and cos and form flowers.


## 5th project: A Text Analysis of Trump's Tweets 
A great exemple on **text mining and sentiment analysis with R**. The dataset is from The Trump Twitter Archive by Brendan Brown, which contains all 35,000+ tweets from the @realDonaldTrump Twitter account from 2009 (the year Trump tweeted for first time) through 2018. We'll filter it for the election period only, June 1, 2015 through November 8, 2016.


## 6th project: Extract Stock Sentiment from News Headlines
In the notebook, we will generate investing insight by applying sentiment analysis on financial news headlines from FINVIZ.com (Web scrapping). Using NLP (NLTK), we can **understand the emotion behind the headlines and predict whether the market feels good or bad about a stock**.


## 7th project: Naïve Bees: Predict Species from Images
In the notebook, we will build a model that can automatically detect honey bees and bumble bees in images. 
The purpose of this project is to see a real application of **SVM (SVC) in classification** and learn how to preprocess data: images from A to Z (grey scaling, normalizing, flattening... etc) + PCA.


## 8th project: Data Science for Social Good: Crime Study
In the notebook, we will explore San Francisco crime data in order to understand the relationship between civilian-reported incidents of crime and police-reported incidents of crime. Along the way we will use table intersection methods to subset our data, aggregation methods to calculate important statistics, and simple visualizations to understand crime trends with **R**. 


## 9th project: Name Game: Gender Prediction using Sound
Analyze the gender distribution of children's book writers and use sound to match names to gender with Python using **fuzzy name matching.**
The same name can be spelled out in a many ways (for example, Marc and Mark, or Elizabeth and Elisabeth). Sound can, therefore, be a better way to match names than spelling. In the project, we will find out the genders of authors that have appeared in the New York Times Best Seller list for Children's Picture books. 


## 10th project: Wrangling and Visualizing Musical Data
Wrangle and visualize musical data to find common chords and compare the styles of different artists using **R**
Apply data-wrangling and visualization tools from the tidyverse to musical data. Find the most common chords and chord progressions in a sample of pop/rock music from the 1950s-1990s, and compare the styles of different artists.
We will see the use of standard TidyVerse tools for R, in particular the tibble data structure and the dplyr and ggplot2


## 11th project: ASL Recognition with Deep Learning
In this project, we will train a **convolutional neural network** to **classify** images of ASL letters (A, B, C only). After loading, examining, and preprocessing the data, we will train a really simple neural network and test its performance.
We will practice the skills from Introduction to Deep Learning in Python and Image Processing with Keras in Python, including building convolutional neural networks to classify images.


## 12th project: Naïve Bees: Deep Learning with Images
We have already seen this project earlier in the seven project using SVM but this time we are building **a deep learning model (CNNs)** that can automatically detect honey bees and bumble bees in images! 
I really loved this project, it gives a great understanding about how CNNs work...
We  will use keras, scikit-learn, scikit-image, and numpy, among other popular Python libraries.
This project is the third part of a series of projects that walk through working with image data, building classifiers using traditional techniques, and leveraging the power of deep learning for computer vision.


## 13th project: Arctic Penguin Exploration: Unraveling Clusters in the Icy Domain with K-means clustering
Unsupervised learning is a critical task in machine learning, and it plays a significant role in this project. The objective is to delve into the information about penguins by utilizing **unsupervised learning techniques** on a thoughtfully curated dataset. By conducting thorough data exploration, extracting meaningful features, and employing advanced algorithms, this project aims to uncover concealed patterns, clusters, and relationships that exist within the dataset.
I have already implemented a K-means model using **R** but Python is more Fun!


## 14th project: Predict Taxi Fares with Random Forests
In this project, we will use regression trees and random forests to find places where New York taxi drivers earn the most with **R**.
We will get to work with the data from a large number of taxi journeys in New York from 2013 and use regression trees and random forests to predict the value of fares and tips, based on location, date and time. While not required, it can help to have some extended experience with the packages dplyr, ggplot2 and randomForests.
The dataset used in this project is a sample from the complete 2013 NYC taxi data, which was originally obtained and published by Chris Whong.


## 15th project: Real-time Insights from Social Media Data
Through this project we will learn to analyze Twitter data and do a deep dive into a hot trend.
In particular, we will do a thorough **analysis of a hot-trend using Python** !
 Data from Twitter-storms is available in near real-time. This means we can learn about the big waves of thoughts and moods around the world as they arise. So of course, we are not going to miss the chance to analyze this treasure trove.
 
 
## 16th project: Generating Keywords for Google Ads
We will learn along this project how to **automatically generate keywords for a search engine marketing campaign using Python**.
We will focus on manipulating Dataframes ! We are mainly tasked with creating a prototype set of keywords for search campaigns for their sofas section.
The most important task in structuring a search engine marketing account is **mapping the right keywords to the right ads** and making sure they send users to the right landing pages.
 
 
## 17th project: Visualizing COVID-19
In this notebook, we will visualize COVID-19 data from the first several weeks of the outbreak to see at what point this virus became a global pandemic and visualize the rise of COVID-19 cases globally with **ggplot2 with R**
The frames we will be seeing are:  **dplyr and ggplot2**, thus we will read many datasets, manipulate them and visualize the results with different plots.


## 18th project: Who's Tweeting? Trump or Trudeau?
In this notebook, we will build a machine learning classifier that knows whether President Trump or Prime Minister Trudeau is tweeting using **Python**, we will choose between **two vectorizations: TFIDF and COUNT with Naive Bayes ** compare the results and then use ** TFIDF vectorization along with Linear SVM ** and finally compare between the two machine learning algorithms ** Linear SVC VS Naive Bayes ** 
To sum up, we'll take a look at classifying two prominent North American politicians using different approaches and compare them with ** the accuracy metric and confusion matrix analysis **. Can we determine if it is Donald Trump or Justin Trudeau based on just a tweet? Let's see! 


## 19th project: Predicting Credit Card Approvals
In this project, we will build an automatic credit card approval predictor using **machine learning techniques with python sklearn**, just like the real banks do.
The dataset used in this project is the **Credit Card Approval** dataset from the UCI Machine Learning Repository.
We will go step by step and tackle the most important steps in structuring a machine learning solution : 
We will analyze the dataset, handle the missing values, pre-process our data by converting the non-numeric data into numeric and scaling the feature values to a uniform range (0-1), we will then apply a machine learning algorithm (Logistic Regression). 
Finally, find the best performing model by performing grid search and cross-validation of five folds. 
We'll end the notebook by storing the best-achieved score and the respective best parameters.


## 20th project: The Hottest Topics in Machine Learning
In this following notebook, we will use Natural Language Processing on NIPS papers to uncover **the trendiest topics in machine learning research**.
For that, a familiarity with Python and pandas is required to complete this Project, as well as experience with Natural Language Processing in Python (sklearn specifically).
The techniques used here to handle large amounts of data can be applied to other text datasets as well.
Along the project, we will load and prepare our dataset, preprocess the text data, draw **a wordcloud** to visualize the data and then analyze the trends using **LDA: latent Dirichlet allocation** which has the aim to **find topics a document belongs to, based on the words in it.**
he techniques used here to handle large amounts of data can be applied to other text datasets as well.


## 21st project: Exploring the Evolution of Linux
In this notebook, we will analyze the evolution of a very famous open-source project – the Linux kernel. The Linux kernel is the heart of some Linux distributions like Debian, Ubuntu or CentOS. Our dataset at hand contains the history of kernel development of almost 13 years (early 2005 - late 2017). We get some insights into the work of the development efforts by:

* identifying the TOP 10 contributors.
* visualizing the commits over the years.

For this Project, we need to be familiar with **Pandas DataFrames, especially the read_csv and groupby functions, as well as working with time series data**. 

